{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    " <a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/video_notebooks/01_pytorch_workflow_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeG__6p8FZHC"
   },
   "source": [
    "# PyTorch Workflow\n",
    "\n",
    "Let's explore a an example PyTorch end-to-end workflow.\n",
    "\n",
    "Resources:\n",
    "* Ground truth notebook - https://github.com/mrdbourke/pytorch-deep-learning/blob/main/01_pytorch_workflow.ipynb\n",
    "* Book version of notebook - https://www.learnpytorch.io/01_pytorch_workflow/\n",
    "* Ask a question - https://github.com/mrdbourke/pytorch-deep-learning/discussions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:07:56.567097Z",
     "start_time": "2024-04-27T14:07:56.356728200Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z_n_NlLzFwEN",
    "outputId": "0f9c66d7-e8af-4020-d53c-17c2e1ede55f"
   },
   "outputs": [],
   "source": [
    "what_were_covering = {1: \"data (prepare and load)\",\n",
    "                      2: \"build model\",\n",
    "                      3: \"fitting the model to data (training)\",\n",
    "                      4: \"making predictions and evaluting a model (inference)\",\n",
    "                      5: \"saving and loading a model\",\n",
    "                      6: \"putting it all together\"}\n",
    "\n",
    "what_were_covering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:07:57.547970500Z",
     "start_time": "2024-04-27T14:07:56.372615600Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "OJN3I__OGWOe",
    "outputId": "1e270c8b-bbb2-4901-b1c7-bcf3e0f1e9f5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn # nn contains all of PyTorch's building blocks for neural networks \n",
    "\n",
    "\n",
    "# Check PyTorch version\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bg1IBDfEG207"
   },
   "source": [
    "## 1. Data (preparing and loading)\n",
    "\n",
    "Data can be almost anything... in machine learning.\n",
    "\n",
    "* Excel speadsheet\n",
    "* Images of any kind\n",
    "* Videos (YouTube has lots of data...)\n",
    "* Audio like songs or podcasts\n",
    "* DNA \n",
    "* Text\n",
    "\n",
    "Machine learning is a game of two parts: \n",
    "1. Get data into a numerical representation.\n",
    "2. Build a model to learn patterns in that numerical representation.\n",
    "\n",
    "To showcase this, let's create some *known* data using the linear regression formula.\n",
    "\n",
    "We'll use a linear regression formula to make a straight line with *known* **parameters**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:07:57.561009800Z",
     "start_time": "2024-04-27T14:07:57.546970100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5hCumNpHHCTU",
    "outputId": "ca51def4-8b84-4b2a-80f8-2da542907aed"
   },
   "outputs": [],
   "source": [
    "# Create *known* parameters\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# Create\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * X + bias \n",
    "\n",
    "X[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:07:57.619361300Z",
     "start_time": "2024-04-27T14:07:57.561009800Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lrPJV_XkJgRT",
    "outputId": "a7c152d0-59d6-455f-c61d-4445f1311014"
   },
   "outputs": [],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GTAEnvLJlq6"
   },
   "source": [
    "### Splitting data into training and test sets (one of the most important concepts in machine learning in general)\n",
    "\n",
    "Let's create a training and test set with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:07:57.620886100Z",
     "start_time": "2024-04-27T14:07:57.576188800Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vpMm7mp_KtNH",
    "outputId": "ff199d0c-6974-47f7-8ba7-e51b7df4c6b6"
   },
   "outputs": [],
   "source": [
    "# Create a train/test split\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:] \n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqArrYcENbhp"
   },
   "source": [
    "How might we better visualize our data?\n",
    "\n",
    "This is where the data explorer's motto comes in!\n",
    "\n",
    "\"Visualize, visualize, visualize!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:07:57.620886100Z",
     "start_time": "2024-04-27T14:07:57.590108200Z"
    },
    "id": "Bgb1fH7FL0O8"
   },
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train,\n",
    "                     train_labels=y_train,\n",
    "                     test_data=X_test,\n",
    "                     test_labels=y_test,\n",
    "                     predictions=None):\n",
    "  \"\"\"\n",
    "  Plots training data, test data and compares predictions.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(10, 7))\n",
    "\n",
    "  # Plot training data in blue\n",
    "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "\n",
    "  # Plot test data in green\n",
    "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "  # Are there predictions?\n",
    "  if predictions is not None:\n",
    "    # Plot the predictions if they exist\n",
    "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "  \n",
    "  # Show the legend\n",
    "  plt.legend(prop={\"size\": 14});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0z7q5QhLOv_q"
   },
   "source": [
    "## 2. Build model \n",
    "\n",
    "Our first PyTorch model!\n",
    "\n",
    "This is very exciting... let's do it!\n",
    "\n",
    "Because we're going to be building classes throughout the course, I'd recommend getting familiar with OOP in Python, to do so you can use the following resource from Real Python: https://realpython.com/python3-object-oriented-programming/\n",
    "\n",
    "What our model does:\n",
    "* Start with random values (weight & bias)\n",
    "* Look at training data and adjust the random values to better represent (or get closer to) the ideal values (the weight & bias values we used to create the data)\n",
    "\n",
    "How does it do so?\n",
    "\n",
    "Through two main algorithms:\n",
    "1. Gradient descent - https://youtu.be/IHZwWFHWa-w\n",
    "2. Backpropagation - https://youtu.be/Ilg3gGewQ5U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:07:57.638576300Z",
     "start_time": "2024-04-27T14:07:57.606227700Z"
    },
    "id": "qirhP4VUkOky"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Create linear regression model class\n",
    "class LinearRegressionModel(nn.Module): # <- almost everything in PyTorch inherhits from nn.Module\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.weights = nn.Parameter(torch.randn(1, # <- start with a random weight and try to adjust it to the ideal weight\n",
    "                                            requires_grad=True, # <- can this parameter be updated via gradient descent?\n",
    "                                            dtype=torch.float)) # <- PyTorch loves the datatype torch.float32\n",
    "    \n",
    "    self.bias = nn.Parameter(torch.randn(1, # <- start with a random bias and try to adjust it to the ideal bias\n",
    "                                         requires_grad=True, # <- can this parameter be updated via gradient descent?\n",
    "                                         dtype=torch.float)) # <- PyTorch loves the datatype torch.float32 \n",
    "    \n",
    "  # Forward method to define the computation in the model\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data\n",
    "    return self.weights * x + self.bias # this is the linear regression formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JH_vD6ICnRUO"
   },
   "source": [
    "### PyTorch model building essentials\n",
    "\n",
    "* torch.nn - contains all of the buildings for computational graphs (a neural network can be considered a computational graph)\n",
    "* torch.nn.Parameter - what parameters should our model try and learn, often a PyTorch layer from torch.nn will set these for us \n",
    "* torch.nn.Module - The base class for all neural network modules, if you subclass it, you should overwrite forward()\n",
    "* torch.optim - this where the optimizers in PyTorch live, they will help with gradient descent\n",
    "* def forward() - All nn.Module subclasses require you to overwrite forward(), this method defines what happens in the forward computation \n",
    "\n",
    "See more of these essential modules via the PyTorch cheatsheet - https://pytorch.org/tutorials/beginner/ptcheat.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_8fP6B0rYnN"
   },
   "source": [
    "### Checking the contents of our PyTorch model\n",
    "\n",
    "Now we've created a model, let's see what's inside...\n",
    "\n",
    "So we can check our model parameters or what's inside our model using `.parameters()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:07:57.638576300Z",
     "start_time": "2024-04-27T14:07:57.623027Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0737rQGNtDxP",
    "outputId": "2a477df1-d234-4db1-c25d-f6eb734cbf86"
   },
   "outputs": [],
   "source": [
    "# Create a random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create an instance of the model (this is a subclass of nn.Module)\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "# Check out the parameters\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:07:57.713208900Z",
     "start_time": "2024-04-27T14:07:57.637577Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdzvifGftWYZ",
    "outputId": "983cdf2a-c582-4fbf-e8d8-9060bb32bb30"
   },
   "outputs": [],
   "source": [
    "# List named parameters\n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlAsG4S-uJO5"
   },
   "source": [
    "### Making prediction using `torch.inference_mode()`\n",
    "\n",
    "To check our model's predictive power, let's see how well it predicts `y_test` based on `X_test`.\n",
    "\n",
    "When we pass data through our model, it's going to run it through the `forward()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:07:57.726136600Z",
     "start_time": "2024-04-27T14:07:57.652868800Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_nRrqGMwm0N",
    "outputId": "f9cbe561-5994-4f99-e4e2-96f70b06fbb8"
   },
   "outputs": [],
   "source": [
    "y_preds = model_0(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:07:57.727136500Z",
     "start_time": "2024-04-27T14:07:57.671711Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCASe_bouVKL",
    "outputId": "cdcc4351-3173-44d2-b854-7bdecedcd0b1"
   },
   "outputs": [],
   "source": [
    "# Make predictions with model\n",
    "with torch.inference_mode():\n",
    "  y_preds = model_0(X_test)\n",
    "  \n",
    "\n",
    "# # You can also do something similar with torch.no_grad(), however, torch.inference_mode() is preferred\n",
    "# with torch.no_grad():\n",
    "#   y_preds = model_0(X_test)\n",
    "\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYHvIyDsxL65"
   },
   "source": [
    "See more on inference mode here - https://twitter.com/PyTorch/status/1437838231505096708?s=20&t=cnKavO9iTgwQ-rfri6u7PQ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:07:57.727136500Z",
     "start_time": "2024-04-27T14:07:57.685042300Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FVREWa_BvzI0",
    "outputId": "a89181a5-a12c-4f52-ef03-e01943da9561"
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FC7cHOnqwWi8"
   },
   "source": [
    "## 3. Train model\n",
    "\n",
    "The whole idea of training is for a model to move from some *unknown* parameters (these may be random) to some *known* parameters.\n",
    "\n",
    "Or in other words from a poor representation of the data to a better representation of the data.\n",
    "\n",
    "One way to measure how poor or how wrong your models predictions are is to use a loss function.\n",
    "\n",
    "* Note: Loss function may also be called cost function or criterion in different areas. For our case, we're going to refer to it as a loss function.\n",
    "\n",
    "Things we need to train:\n",
    "\n",
    "* **Loss function:** A function to measure how wrong your model's predictions are to the ideal outputs, lower is better.\n",
    "* **Optimizer:** Takes into account the loss of a model and adjusts the model's parameters (e.g. weight & bias in our case) to improve the loss function - https://pytorch.org/docs/stable/optim.html#module-torch.optim\n",
    "  * Inside the optimizer you'll often have to set two parameters:\n",
    "    * `params` - the model parameters you'd like to optimize, for example `params=model_0.parameters()`\n",
    "    * `lr` (learning rate) - the learning rate is a hyperparameter that defines how big/small the optimizer changes the parameters with each step (a small `lr` results in small changes, a large `lr` results in large changes)\n",
    "\n",
    "And specifically for PyTorch, we need:\n",
    "* A training loop\n",
    "* A testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:07:57.740252400Z",
     "start_time": "2024-04-27T14:07:57.700669800Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gR7Xy8FqQ1x1",
    "outputId": "85ea9234-292b-4269-c450-3a9088e3d65a"
   },
   "outputs": [],
   "source": [
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:07:57.761552500Z",
     "start_time": "2024-04-27T14:07:57.718216700Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MeA8r0whRzVM",
    "outputId": "3bf7b029-3a6d-4f4d-cb37-e493fff66f16"
   },
   "outputs": [],
   "source": [
    "# Check out our model's parameters (a parameter is a value that the model sets itself)\n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:07:58.575652200Z",
     "start_time": "2024-04-27T14:07:57.732244200Z"
    },
    "id": "FhpnOr3vR5jI"
   },
   "outputs": [],
   "source": [
    "# Setup a loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Setup an optimizer (stochastic gradient descent)\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), # we want to optimize the parameters present in our model\n",
    "                            lr=0.001) # lr = learning rate = possibly the most important hyperparameter you can set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zR0wku4LUzr7"
   },
   "source": [
    "> **Q:** Which loss function and optimizer should I use?\n",
    ">\n",
    "> **A:** This will be problem specific. But with experience, you'll get an idea of what works and what doesn't with your particular problem set.\n",
    ">\n",
    "> For example, for a regression problem (like ours), a loss function of `nn.L1Loss()` and an optimizer like `torch.optim.SGD()` will suffice.\n",
    ">\n",
    "> But for a classification problem like classifying whether a photo is of a dog or a cat, you'll likely want to use a loss function of `nn.BCELoss()` (binary cross entropy loss). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffr8kYJTXwkD"
   },
   "source": [
    "### Building a training loop (and a testing loop) in PyTorch\n",
    "\n",
    "A couple of things we need in a training loop:\n",
    "0. Loop through the data and do...\n",
    "1. Forward pass (this involves data moving through our model's `forward()` functions) to make predictions on data - also called forward propagation \n",
    "2. Calculate the loss (compare forward pass predictions to ground truth labels)\n",
    "3. Optimizer zero grad\n",
    "4. Loss backward - move backwards through the network to calculate the gradients of each of the parameters of our model with respect to the loss (**backpropagation** - https://www.youtube.com/watch?v=tIeHLnjs5U8)\n",
    "5. Optimizer step - use the optimizer to adjust our model's parameters to try and improve the loss (**gradient descent** - https://youtu.be/IHZwWFHWa-w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:07:58.687738400Z",
     "start_time": "2024-04-27T14:07:58.578924Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TV8WOxYPaTlP",
    "outputId": "e05110b7-2289-48c9-e99c-cfca09e0f9b3"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# An epoch is one loop through the data... (this is a hyperparameter because we've set it ourselves)\n",
    "epochs = 200\n",
    "\n",
    "# Track different values\n",
    "epoch_count = [] \n",
    "loss_values = []\n",
    "test_loss_values = [] \n",
    "\n",
    "### Training\n",
    "# 0. Loop through the data\n",
    "for epoch in range(epochs): \n",
    "  # Set the model to training mode\n",
    "  model_0.train() # train mode in PyTorch sets all parameters that require gradients to require gradients \n",
    "\n",
    "  # 1. Forward pass\n",
    "  y_pred = model_0(X_train)\n",
    "\n",
    "  # 2. Calculate the loss\n",
    "  loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "  # 3. Optimizer zero grad\n",
    "  optimizer.zero_grad() \n",
    "\n",
    "  # 4. Perform backpropagation on the loss with respect to the parameters of the model (calculate gradients of each parameter)\n",
    "  loss.backward()\n",
    "\n",
    "  # 5. Step the optimizer (perform gradient descent)\n",
    "  optimizer.step() # by default how the optimizer changes will acculumate through the loop so... we have to zero them above in step 3 for the next iteration of the loop\n",
    "\n",
    "  ### Testing\n",
    "  model_0.eval() # turns off different settings in the model not needed for evaluation/testing (dropout/batch norm layers)\n",
    "  with torch.inference_mode(): # turns off gradient tracking & a couple more things behind the scenes - https://twitter.com/PyTorch/status/1437838231505096708?s=20&t=aftDZicoiUGiklEP179x7A\n",
    "  # with torch.no_grad(): # you may also see torch.no_grad() in older PyTorch code\n",
    "    # 1. Do the forward pass \n",
    "    test_pred = model_0(X_test)\n",
    "\n",
    "    # 2. Calculate the loss\n",
    "    test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "  # Print out what's happening'\n",
    "  if epoch % 10000 == 0:\n",
    "    epoch_count.append(epoch)\n",
    "    loss_values.append(loss)\n",
    "    test_loss_values.append(test_loss)\n",
    "    print(f\"Epoch: {epoch} | Loss: {loss} | Test loss: {test_loss}\")\n",
    "    # Print out model state_dict()\n",
    "    print(model_0.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:07:59.737689500Z",
     "start_time": "2024-04-27T14:07:59.690678500Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O6EZVQi1759Y",
    "outputId": "e1ea02bd-efe8-4655-eea3-50e88e951189"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array(torch.tensor(loss_values).numpy()), test_loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-27T14:08:01.456657Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "ccr-GEYe7da1",
    "is_executing": true,
    "outputId": "68b6980f-85ab-4811-cd53-be0d1091ff10"
   },
   "outputs": [],
   "source": [
    "# Plot the loss curves\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "plt.plot(epoch_count, np.array(torch.tensor(loss_values).numpy()), label=\"Train loss\")\n",
    "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
    "plt.title(\"Training and test loss curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:03:27.385540Z",
     "start_time": "2024-04-27T14:03:27.027595Z"
    },
    "id": "vfl9oAt_09Fd"
   },
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "  y_preds_new = model_0(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T13:24:36.268605100Z",
     "start_time": "2024-04-27T13:24:36.228002300Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3Y-ilS3jCdG",
    "outputId": "4bc413d2-3b5b-4f4d-c822-5f3693f3796d"
   },
   "outputs": [],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T13:24:38.337343200Z",
     "start_time": "2024-04-27T13:24:38.318126100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cE8uVRUeg39p",
    "outputId": "9abe949e-3ba1-4d7e-91ee-f0dc59371641"
   },
   "outputs": [],
   "source": [
    "weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-27T13:24:42.202413300Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "f_gboBMSl13p",
    "outputId": "3c5bce1a-ad41-44ac-bf7f-326d4b5c4308"
   },
   "outputs": [],
   "source": [
    "plot_predictions(predictions=y_preds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "9y-u_rVC16XJ",
    "outputId": "354933d7-7c14-46c5-9a71-eee4cb7200c2"
   },
   "outputs": [],
   "source": [
    "plot_predictions(predictions=y_preds_new);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXusQ2JP1_S1"
   },
   "source": [
    "## Saving a model in PyTorch\n",
    "\n",
    "There are three main methods you should about for saving and loading models in PyTorch.\n",
    "\n",
    "1. `torch.save()` - allows you save a PyTorch object in Python's pickle format \n",
    "2. `torch.load()` - allows you load a saved PyTorch object\n",
    "3. `torch.nn.Module.load_state_dict()` - this allows to load a model's saved state dictionary \n",
    "\n",
    "PyTorch save & load code tutorial + extra-curriculum - https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a0iaBiX5JAG",
    "outputId": "dbe254f6-1696-4fa8-a3d3-619aebf930aa"
   },
   "outputs": [],
   "source": [
    "# Saving our PyTorch model\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory \n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path\n",
    "MODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_0.state_dict(),\n",
    "           f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Os6BGzXT54Xq",
    "outputId": "2529729e-a3c5-486a-e913-b3031a5fe9ab"
   },
   "outputs": [],
   "source": [
    "!ls -l models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uib6vQMB7Ds1"
   },
   "source": [
    "## Loading a PyTorch model\n",
    "\n",
    "Since we saved our model's `state_dict()` rather the entire model, we'll create a new instance of our model class and load the saved `state_dict()` into that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9U-uXVaC85PP",
    "outputId": "a2c8ea18-fbb5-49a7-d985-eab4a76b2875"
   },
   "outputs": [],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lTghUxOH89lz",
    "outputId": "354c3ac5-96d5-499b-d734-d3e56b8ba3e7"
   },
   "outputs": [],
   "source": [
    "# To load in a saved state_dict we have to instantiate a new instance of our model class\n",
    "loaded_model_0 = LinearRegressionModel()\n",
    "\n",
    "# Load the saved state_dict of model_0 (this will update the new instance with updated parameters)\n",
    "loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_44x4te89OjW",
    "outputId": "a8537d36-f89a-4409-90b3-3563f836231e"
   },
   "outputs": [],
   "source": [
    "loaded_model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxPDLIU09Q0i",
    "outputId": "887f395e-1719-4f68-f3d9-23e17088eb14"
   },
   "outputs": [],
   "source": [
    "# Make some predictions with our loaded model\n",
    "loaded_model_0.eval()\n",
    "with torch.inference_mode():\n",
    "  loaded_model_preds = loaded_model_0(X_test)\n",
    "\n",
    "loaded_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3BP9cufq99K-",
    "outputId": "191daad3-6df1-4018-95c9-de755eb4f381"
   },
   "outputs": [],
   "source": [
    "# Make some models preds\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "  y_preds = model_0(X_test)\n",
    "\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSbACbvI94XX",
    "outputId": "853b8d5f-7830-41c2-ffd2-93a7fc0b2270"
   },
   "outputs": [],
   "source": [
    "# Compare loaded model preds with original model preds\n",
    "y_preds == loaded_model_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQHmmLBo9_ji"
   },
   "source": [
    "## 6. Putting it all together\n",
    "\n",
    "Let's go back through the steps above and see it all in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "TY16oebx_4yK",
    "outputId": "d0d09199-ab74-45b0-fa8f-ee86ecaa5f3b"
   },
   "outputs": [],
   "source": [
    "# Import PyTorch and matplotlib\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check PyTorch version\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l91cJBlNAZ7m"
   },
   "source": [
    "Create device-agnostic code.\n",
    "\n",
    "This means if we've got access to a GPU, our code will use it (for potentially faster computing).\n",
    "\n",
    "If no GPU is available, the code will default to using CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hRCrpBhAj9G",
    "outputId": "d1f41115-e110-49ba-822b-748f48d86bd3"
   },
   "outputs": [],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lMKxKvN_1yP"
   },
   "source": [
    "### 6.1 Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StBcwzuA_4GP",
    "outputId": "620dca7c-3409-47f9-9a50-f051505125d3"
   },
   "outputs": [],
   "source": [
    "# Create some data using the linear regression formula of y = weight * X + bias\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# Create range values\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "\n",
    "# Create X and y (features and labels)\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1) # without unsqueeze, errors will pop up\n",
    "y = weight * X + bias\n",
    "X[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mGpxaIDsCDBN",
    "outputId": "8ff5f597-3f3f-4324-c015-8b6b641163de"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4tidX_5CnVx"
   },
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train,\n",
    "                     train_labels=y_train,\n",
    "                     test_data=X_test,\n",
    "                     test_labels=y_test,\n",
    "                     predictions=None):\n",
    "  \"\"\"\n",
    "  Plots training data, test data and compares predictions.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(10, 7))\n",
    "\n",
    "  # Plot training data in blue\n",
    "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "\n",
    "  # Plot test data in green\n",
    "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "  # Are there predictions?\n",
    "  if predictions is not None:\n",
    "    # Plot the predictions if they exist\n",
    "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "  \n",
    "  # Show the legend\n",
    "  plt.legend(prop={\"size\": 14});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "2go898QeCXJY",
    "outputId": "ca6406c0-6604-4ff3-8dd4-25aae5a44333"
   },
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "# Note: if you don't have the plot_predictions() function loaded, this will error\n",
    "%matplotlib notebook\n",
    "plot_predictions(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2jU9bN1Cgt0"
   },
   "source": [
    "### 6.2 Building a PyTorch Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wx8c6kF5Cyp_",
    "outputId": "eeb9bcc0-a227-4cca-cc4c-96021e6c0d23"
   },
   "outputs": [],
   "source": [
    "# Create a linear model by subclassing nn.Module\n",
    "class LinearRegressionModelV2(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # Use nn.Linear() for creating the model parameters / also called: linear transform, probing layer, fully connected layer, dense layer\n",
    "    self.linear_layer = nn.Linear(in_features=1,\n",
    "                                  out_features=1)\n",
    "    \n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    return self.linear_layer(x)\n",
    "\n",
    "# Set the manual seed\n",
    "torch.manual_seed(42)\n",
    "model_1 = LinearRegressionModelV2()\n",
    "model_1, model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9DmOPoTFIC4",
    "outputId": "4f37c379-8cb8-4080-9615-f2d936abd829"
   },
   "outputs": [],
   "source": [
    "model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iq9DxUEyEEvX",
    "outputId": "66921f3d-c706-40dc-99ed-6b35f7ec92dc"
   },
   "outputs": [],
   "source": [
    "X_train[:5], y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3gCbh6Am8go",
    "outputId": "f2121256-84b6-4908-d3bd-084ac636a156"
   },
   "outputs": [],
   "source": [
    "# Check the model current device\n",
    "next(model_1.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMNMpAavEFnC",
    "outputId": "d3aa990d-455f-4808-fc01-b229be4eb853"
   },
   "outputs": [],
   "source": [
    "# Set the model to use the target device\n",
    "model_1.to(device)\n",
    "next(model_1.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9h7xgGbCnWI1",
    "outputId": "74a3d084-6c7b-443b-e217-401985507575"
   },
   "outputs": [],
   "source": [
    "model_1.state_dict() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEfyHhtrm45n"
   },
   "source": [
    "### 6.3 Training\n",
    "\n",
    "For training we need:\n",
    "* Loss function\n",
    "* Optimizer\n",
    "* Training loop\n",
    "* Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BjW4zUvtnOrj"
   },
   "outputs": [],
   "source": [
    "# Setup loss function\n",
    "loss_fn = nn.L1Loss() # same as MAE\n",
    "\n",
    "# Setup our optimizer\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(), \n",
    "                            lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GyAumLw3n2Hy",
    "outputId": "207e60c6-83b6-4524-da0b-ddf7d7db52e2"
   },
   "outputs": [],
   "source": [
    "# Let's write a training loop\n",
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 200000\n",
    "\n",
    "# Put data on the target device (device agnostic code for data) \n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  model_1.train()\n",
    "\n",
    "  # 1. Forward pass\n",
    "  y_pred = model_1(X_train)\n",
    "\n",
    "  # 2. Calculate the loss\n",
    "  loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "  # 3. Optimizer zero grad\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  # 4. Perform backpropagation\n",
    "  loss.backward()\n",
    "\n",
    "  # 5. Optimizer step\n",
    "  optimizer.step()\n",
    "\n",
    "  ### Testing\n",
    "  model_1.eval()\n",
    "  with torch.inference_mode():\n",
    "    test_pred = model_1(X_test)\n",
    "\n",
    "    test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "  # Print out what's happening\n",
    "  if epoch % 10 == 0: \n",
    "    print(f\"Epoch: {epoch} | Loss: {loss} | Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2qJjO4ko6x_",
    "outputId": "7125869b-b8f4-4ee2-ab14-571afa54c316"
   },
   "outputs": [],
   "source": [
    "model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28o1G0gnpYRj",
    "outputId": "ae9098ca-52bb-440f-84f6-7979f2ccd2c5"
   },
   "outputs": [],
   "source": [
    "weight, bias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_Y2nC9tpaDz"
   },
   "source": [
    "### 6.4 Making and evaluating predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ngw4JbJQqubf",
    "outputId": "6a05ad5c-98bd-4e01-e951-a40bf84e46a0"
   },
   "outputs": [],
   "source": [
    "# Turn model into evaluation mode\n",
    "model_1.eval()\n",
    "\n",
    "# Make predictions on the test data\n",
    "with torch.inference_mode():\n",
    "  y_preds = model_1(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "uUIbkzHIq5U8",
    "outputId": "d1e6ead5-4ce9-42d9-c2a7-332e143408be"
   },
   "outputs": [],
   "source": [
    "# Check out our model predictions visually\n",
    "plot_predictions(predictions=y_preds.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qdw43z6rEZB"
   },
   "source": [
    "### 6.5 Saving & loading a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YkPtfsseriP_",
    "outputId": "5cc74c45-2adc-43d5-806c-b1446c199eee"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path\n",
    "MODEL_NAME = \"01_pytorch_workflow_model_1.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_1.state_dict(),\n",
    "           f=MODEL_SAVE_PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5n_xTjssNZ2",
    "outputId": "14c63c26-3ae1-458c-d172-2ba03e99479d"
   },
   "outputs": [],
   "source": [
    "model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yj8GttgnsNXq",
    "outputId": "d934cb26-e89a-4344-f904-26d6cb06487c"
   },
   "outputs": [],
   "source": [
    "# Load a PyTorch model\n",
    "\n",
    "# Create a new instance of lienar regression model V2\n",
    "loaded_model_1 = LinearRegressionModelV2()\n",
    "\n",
    "# Load the saved model_1 state_dict\n",
    "loaded_model_1.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "\n",
    "# Put the loaded model to device\n",
    "loaded_model_1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4pSqRcShsNVE",
    "outputId": "fde1b8e2-cab1-45e8-e8d4-2b2255a2b9d7"
   },
   "outputs": [],
   "source": [
    "next(loaded_model_1.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1nhEK4FsNSy",
    "outputId": "85d3f5b0-52b8-444f-c1cf-f2d2752cc78c"
   },
   "outputs": [],
   "source": [
    "loaded_model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOZBAa-JsNQJ",
    "outputId": "9b722c03-be13-44a8-934d-33613490bb4d"
   },
   "outputs": [],
   "source": [
    "# Evaluate loaded model\n",
    "loaded_model_1.eval()\n",
    "with torch.inference_mode():\n",
    "  loaded_model_1_preds = loaded_model_1(X_test)\n",
    "y_preds == loaded_model_1_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eh1HuUNmtxt_"
   },
   "source": [
    "## Exercises & Extra-curriculum\n",
    "\n",
    "For exercise & extra-curriculum, refer to: https://www.learnpytorch.io/01_pytorch_workflow/#exercises "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DNZm0YkvEWZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPiZqHPF/YamI5YlikNi4KW",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "01_pytorch_workflow_video.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
